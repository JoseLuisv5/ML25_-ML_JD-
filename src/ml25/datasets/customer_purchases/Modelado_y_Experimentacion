# svm_lineal.py
# Uso:
#   python svm_lineal.py
#   python svm_lineal.py --features "RUTA\train_features_per_customer.csv" --outdir "RUTA\SVM_out"

import os, json, argparse, warnings
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

from sklearn.model_selection import train_test_split, StratifiedKFold, cross_validate
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline
from sklearn.svm import LinearSVC
from sklearn.metrics import (
    accuracy_score, f1_score, roc_auc_score, average_precision_score,
    confusion_matrix, RocCurveDisplay, PrecisionRecallDisplay
)
from sklearn.base import clone
from joblib import dump

warnings.filterwarnings("ignore")

DEFAULT_FEATURES_DIR = r"C:\Users\jlvh0\Documents\ML25_-ML_JD-\src\ml25\datasets\customer_purchases\out_features_agg\train"
DEFAULT_FEATURES_BASENAME = "train_features_per_customer.csv"

def ensure(path):
    os.makedirs(path, exist_ok=True); return path

def parse_args():
    p = argparse.ArgumentParser()
    p.add_argument("--features", type=str, default=None)
    p.add_argument("--outdir", type=str, default=None)
    p.add_argument("--test_size", type=float, default=0.25)
    p.add_argument("--kfolds", type=int, default=5)
    p.add_argument("--C", type=float, default=1.0)
    p.add_argument("--random_state", type=int, default=42)
    return p.parse_args()

def resolve_features_path(path_arg):
    if path_arg and os.path.isfile(path_arg): return path_arg
    cand1 = os.path.join(DEFAULT_FEATURES_DIR, DEFAULT_FEATURES_BASENAME)
    if os.path.isfile(cand1): return cand1
    cand2 = os.path.join(os.getcwd(), DEFAULT_FEATURES_BASENAME)
    if os.path.isfile(cand2): return cand2
    raise SystemExit(
        "No encontré el CSV de features. Pasa --features o coloca 'train_features_per_customer.csv' en:\n"
        f"- {DEFAULT_FEATURES_DIR}\n- {os.getcwd()}"
    )

def load_features(path):
    df = pd.read_csv(path)
    if "customer_id" not in df.columns: raise SystemExit("Falta 'customer_id' en el CSV.")
    ids = df["customer_id"].astype(int).values
    y_col = "y" if "y" in df.columns else ("label" if "label" in df.columns else None)
    if y_col is None: raise SystemExit("Falta columna objetivo ('y' o 'label').")
    y = df[y_col].astype(int).values
    if len(np.unique(y)) < 2: raise SystemExit("La etiqueta tiene una sola clase; no se puede entrenar.")
    X = df.drop(columns=[c for c in ["customer_id","y","label"] if c in df.columns])
    return X, y, ids

def ajuste_kfolds(y, k):
    binc = np.bincount(y)
    min_clase = int(binc.min()) if binc.size > 1 else 0
    return max(2, min(k, min_clase)) if min_clase > 0 else 2

def entrenar_y_evaluar(X, y, C=1.0, test_size=0.25, kfolds=5, rs=42, outdir="."):
    X = X.values.astype(np.float32)
    pipe = Pipeline([
        ("scaler", StandardScaler(with_mean=False)),
        ("clf",    LinearSVC(C=C, class_weight="balanced", random_state=rs))
    ])
    k_adj = ajuste_kfolds(y, kfolds)
    cv = StratifiedKFold(n_splits=k_adj, shuffle=True, random_state=rs)

    def safe_cv(sc_list):
        try:
            s = cross_validate(pipe, X, y, cv=cv, scoring=sc_list, n_jobs=-1, return_train_score=False, error_score="raise")
            out = {}
            for name in (sc_list if isinstance(sc_list, (list,tuple)) else [sc_list]):
                out[f"cv_{name}_mean"] = float(np.nanmean(s[f"test_{name}"]))
            return out
        except Exception:
            names = sc_list if isinstance(sc_list, (list,tuple)) else [sc_list]
            return {f"cv_{n}_mean": float("nan") for n in names}

    cv_metrics = safe_cv(["accuracy","f1","roc_auc","average_precision"])

    X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=test_size, stratify=y, random_state=rs)
    pipe.fit(X_tr, y_tr)

    scores_te = pipe.decision_function(X_te)
    y_pred = pipe.predict(X_te)

    m = {
        **cv_metrics,
        "test_accuracy": float(accuracy_score(y_te, y_pred)),
        "test_f1": float(f1_score(y_te, y_pred, zero_division=0)),
        "test_roc_auc": float(roc_auc_score(y_te, scores_te)) if len(np.unique(y_te))>1 else float("nan"),
        "test_pr_auc": float(average_precision_score(y_te, scores_te)),
        "kfolds_used": int(k_adj),
        "C": float(C),
        "test_size": float(test_size),
        "random_state": int(rs)
    }

    fig = plt.figure(figsize=(12, 4))
    ax1 = fig.add_subplot(1,3,1)
    PrecisionRecallDisplay.from_predictions(y_te, scores_te, ax=ax1); ax1.set_title("Precision-Recall")
    ax2 = fig.add_subplot(1,3,2)
    try:
        RocCurveDisplay.from_predictions(y_te, scores_te, ax=ax2); ax2.set_title("ROC")
    except Exception:
        ax2.axis("off"); ax2.set_title("ROC (no disponible)")
    ax3 = fig.add_subplot(1,3,3)
    cm = confusion_matrix(y_te, y_pred); im = ax3.imshow(cm, interpolation="nearest")
    ax3.set_title("Matriz de confusión"); ax3.set_xticks([0,1]); ax3.set_yticks([0,1])
    ax3.set_xlabel("Predicha"); ax3.set_ylabel("Real")
    for (i,j), v in np.ndenumerate(cm): ax3.text(j, i, int(v), ha="center", va="center")
    fig.colorbar(im, ax=ax3, fraction=0.046, pad=0.04); plt.tight_layout()

    ensure(outdir)
    fig_path = os.path.join(outdir, "svm_eval.png"); fig.savefig(fig_path, dpi=160); plt.close(fig)
    model_split_path = os.path.join(outdir, "svm_lineal.joblib"); dump(pipe, model_split_path)
    with open(os.path.join(outdir, "metrics.json"), "w", encoding="utf-8") as f: json.dump(m, f, indent=2, ensure_ascii=False)

    return m, fig_path, model_split_path, pipe

def entrenar_full_y_predecir(pipe_template, X_full, y_full, ids_full, outdir):
    model = clone(pipe_template); model.fit(X_full.values.astype(np.float32), y_full.astype(int))
    y_hat = model.predict(X_full.values.astype(np.float32)).astype(int)
    pred = pd.DataFrame({"customer_id": ids_full.astype(int), "will_buy": y_hat})
    pred_path = os.path.join(outdir, "svm_predictions.csv"); pred.to_csv(pred_path, index=False)
    model_full_path = os.path.join(outdir, "svm_lineal_full.joblib"); dump(model, model_full_path)
    return pred_path, model_full_path

def main():
    args = parse_args()
    outdir = args.outdir or os.path.join(os.getcwd(), "SVM_out"); ensure(outdir)
    feat_path = resolve_features_path(args.features)

    print("Usando features:", feat_path)
    print("Outdir:", outdir)

    X, y, ids = load_features(feat_path)
    m, fig_path, model_split_path, pipe = entrenar_y_evaluar(
        X, y, C=args.C, test_size=args.test_size, kfolds=args.kfolds, rs=args.random_state, outdir=outdir
    )
    pred_path, model_full_path = entrenar_full_y_predecir(pipe, X, y, ids, outdir)

    print("OK.")
    print("Figuras:", fig_path)
    print("Modelo (split):", model_split_path)
    print("Modelo (full) :", model_full_path)
    print("Predicciones :", pred_path)
    print(json.dumps(m, indent=2, ensure_ascii=False))

if __name__ == "__main__":
    main()
